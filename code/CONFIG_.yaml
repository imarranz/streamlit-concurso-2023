
metricas:
  exactitud: "**Exactitud de clasificación**. La exactitud es una métrica de clasificación que mide el porcentaje de instancias correctamente clasificadas del número total de instancias. Es una métrica sencilla que proporciona una medida rápida e intuitiva del rendimiento de un modelo. Sin embargo, tiene sus limitaciones, especialmente cuando se trata de conjuntos de datos desequilibrados, donde la cantidad de instancias en una clase es significativamente mayor que la otra.\n A pesar de sus limitaciones, la exactitud se usa ampliamente en diversas aplicaciones, como la clasificación de textos, el reconocimiento de imágenes y la detección de fraudes. En la práctica, a menudo se usa junto con otras métricas de evaluación para proporcionar una comprensión más completa del rendimiento del modelo de clasificación."
  precision: "**Precisión media**. Resumen de la curva de recuperación de precisión. La precisión promedio es una métrica de clasificación que mide la calidad de las predicciones de un modelo en función de la curva de recuperación de precisión. La precisión es el número de verdaderos positivos dividido por el número de verdaderos positivos y falsos positivos, mientras que el recuerdo es el número de verdaderos positivos dividido por la suma de verdaderos positivos y falsos negativos. La curva de recuperación de precisión es una representación gráfica de la compensación entre precisión y recuperación a medida que cambia el umbral de clasificación.\n La puntuación de precisión promedio calcula el área bajo la curva de recuperación de precisión y proporciona un número único que resume la calidad de las predicciones del modelo. Es una métrica útil, especialmente para conjuntos de datos desequilibrados, donde la cantidad de instancias en una clase es significativamente mayor que la otra. En tales casos, la precisión puede no ser una métrica apropiada ya que el modelo puede clasificar todas las instancias como la clase mayoritaria, lo que lleva a predicciones de alta precisión pero de baja calidad.\n La puntuación de precisión promedio se usa comúnmente en varias aplicaciones, como la recuperación de información, los sistemas de recomendación y el diagnóstico médico. Proporciona una evaluación más completa del rendimiento del modelo al considerar tanto la precisión como la recuperación, lo que la convierte en una métrica valiosa para evaluar los modelos de clasificación."
  f1: "**F1: Media armónica de precisión y recuperación**. La puntuación F1 es una métrica de clasificación que tiene en cuenta tanto la precisión como la recuperación, y proporciona un único número que resume la calidad de las predicciones de un modelo. La precisión es el número de verdaderos positivos dividido por la suma de verdaderos positivos y falsos positivos, mientras que el recuerdo es el número de verdaderos positivos dividido por la suma de verdaderos positivos y falsos negativos. La puntuación F1 es la media armónica de precisión y recuperación, dando el mismo peso a ambas métricas.\n La puntuación F1 es útil en situaciones en las que tanto la precisión como la recuperación son igualmente importantes, como en los problemas de clasificación binaria en los que tanto los falsos positivos como los falsos negativos son costosos. También es una métrica útil cuando se trata de conjuntos de datos desequilibrados, donde la cantidad de instancias en una clase es significativamente mayor que la otra.\n El puntaje F1 se usa comúnmente en varias aplicaciones, como clasificación de texto, análisis de sentimientos y diagnóstico médico. Proporciona una evaluación más equilibrada del rendimiento del modelo en comparación con la precisión, que puede estar sesgada hacia la clase mayoritaria en conjuntos de datos desequilibrados. En general, el puntaje F1 es una métrica valiosa para evaluar los modelos de clasificación y se usa ampliamente en la práctica."
  entropia: "**Pérdida de entropía cruzada**. La pérdida de entropía cruzada es una métrica de clasificación que mide la diferencia entre la distribución de probabilidad predicha y la distribución de probabilidad real. Se calcula como la verosimilitud logarítmica negativa de las etiquetas de clase verdaderas dadas las probabilidades de clase pronosticadas. En otras palabras, penaliza al modelo por hacer predicciones incorrectas y lo recompensa por hacer predicciones correctas.\n La pérdida de entropía cruzada es una métrica útil para evaluar modelos de clasificación porque tiene en cuenta la incertidumbre de las predicciones. Proporciona una medida continua del rendimiento del modelo que se puede utilizar para comparar diferentes modelos y ajustar hiperparámetros.\n La pérdida de entropía cruzada se usa comúnmente como la función objetivo para entrenar modelos de clasificación, donde el objetivo es minimizar la pérdida. También se utiliza como métrica para evaluar el rendimiento del modelo en un conjunto de validación o de prueba. La pérdida de entropía cruzada se usa ampliamente en varias aplicaciones, como el procesamiento del lenguaje natural, la clasificación de imágenes y el reconocimiento de voz.\n En resumen, la pérdida de entropía cruzada es una métrica valiosa para evaluar los modelos de clasificación porque tiene en cuenta la incertidumbre de las predicciones y proporciona una medida continua del rendimiento del modelo. Es ampliamente utilizado en la práctica y es una herramienta esencial para desarrollar y mejorar los modelos de clasificación." 
  precision: "**Precisión**. La precisión es una métrica de clasificación que mide la proporción de instancias positivas pronosticadas correctamente del número total de instancias pronosticadas como positivas. Representa la capacidad del modelo para evitar falsos positivos, es decir, instancias que se predicen como positivas pero que en realidad son negativas.\n La precisión es una métrica valiosa, especialmente en aplicaciones donde el costo de los falsos positivos es alto, como en el diagnóstico médico o la detección de fraudes. Una puntuación de precisión alta indica que el modelo está haciendo pocas predicciones positivas falsas, lo cual es crucial en tales aplicaciones.\n Sin embargo, la precisión no tiene en cuenta los falsos negativos, es decir, las instancias que en realidad son positivas pero se predicen como negativas. Por lo tanto, la precisión debe utilizarse junto con otras métricas, como la recuperación y la puntuación F1, para proporcionar una evaluación más completa del rendimiento del modelo.\n La precisión se usa comúnmente en varias aplicaciones, como el filtrado de correo no deseado, el análisis de sentimientos y el reconocimiento de imágenes. Es una métrica útil para evaluar la capacidad del modelo para realizar predicciones positivas precisas, lo que la convierte en una herramienta esencial para desarrollar y mejorar los modelos de clasificación.\n La precisión es la relación tp / (tp + fp) donde tp es el número de verdaderos positivos y fp el número de falsos positivos. La precisión es intuitivamente la capacidad del clasificador de no etiquetar como positiva una muestra que es negativa. El mejor valor es 1 y el peor valor es 0."  
  recall: "**Recall**. _Recall_ es la relación tp / (tp + fn) donde tp es el número de verdaderos positivos y fn el número de falsos negativos. _Recall_ es, intuitivamente, la capacidad del clasificador para encontrar todas las muestras positivas. El mejor valor es 1 y el peor valor es 0.\n _Recall_, también conocida como sensibilidad, es una métrica de clasificación que mide la proporción de instancias positivas pronosticadas correctamente del número total de instancias positivas en el conjunto de datos. Representa la capacidad del modelo para identificar todas las instancias positivas, incluidas aquellas que son difíciles de identificar.\n _Recall_ es una métrica valiosa, especialmente en aplicaciones donde el costo de los falsos negativos es alto, como en el diagnóstico médico o la predicción del riesgo crediticio. Una puntuación de recuerdo alta indica que el modelo está haciendo pocas predicciones negativas falsas, lo cual es crucial en tales aplicaciones.\n Sin embargo, _recall_ no tiene en cuenta los falsos positivos, es decir, las instancias que en realidad son negativas pero se predicen como positivas. Por lo tanto, _recall_ debe utilizarse junto con otras métricas, como la precisión y la puntuación F1, para proporcionar una evaluación más completa del rendimiento del modelo.\n _Recall_ se usa comúnmente en varias aplicaciones, como la detección de enfermedades, la detección de anomalías y la detección de fraudes. Es una métrica útil para evaluar la capacidad del modelo para identificar todas las instancias positivas, lo que la convierte en una herramienta esencial para desarrollar y mejorar los modelos de clasificación."  
